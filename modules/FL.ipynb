{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning Pipeline\n",
    "\n",
    "This annotated notebook explains the pipeline **step by step**, with:\n",
    "- short introductions before each code cell;\n",
    "- comments at the top of every cell describing *what it does* and *how to check the result*;\n",
    "- a **checklist**, **troubleshooting tips**, a **glossary**, and suggested exercises.\n",
    "\n",
    "> **Learning Objectives**\n",
    "> - Understand the end‑to‑end flow of a Federated Learning (FL) pipeline: preprocessing → training → evaluation → saving artifacts.\n",
    "> - Learn to read and adapt components (dataset, model, training loop, metrics).\n",
    "> - Run experiments (saving results).\n",
    "\n",
    "> **Prerequisites**\n",
    "> - Intermediate Python; experience with PyTorch and scikit‑learn.\n",
    "> - Basic ML concepts: train/val/test split, overfitting, metrics.\n",
    "> - Introductory knowledge of FL (clients, server/aggregator, training rounds).\n",
    "\n",
    "> **Mini Glossary (FL)**\n",
    "> - **Client**: A device/site (e.g., hospital, phone) that trains locally on private data.\n",
    "> - **Server**:The coordinator distributes the starting model, communicates with clients, collects client updates, and distributes new models.\n",
    "> - **Aggregator/Aggregation Method**:  Method chosen to aggregate all client models and create the new global model.\n",
    "> - **Round**: One cycle of local training → sending updates → aggregation.\n",
    "> - **Aggregation frequency**: Number of epochs between sending weights to the server.\n",
    "> - **Federated Averaging (FedAvg)**: Standard method to average/aggregate client model weights.\n",
    "> - **IID Data**: Customer data follows the same distribution across all clients (homogeneity).\n",
    "> - **Non‑IID Data**: Client data may follow different distributions (heterogeneity).\n",
    "> - **Global model**: Model sent by the server to all clients\n",
    "> - **Local model**: Model trained by the client on its data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import module\n",
    "**Environment setup and library imports.**\n",
    "\n",
    "This section imports all required libraries:\n",
    " - Data handling: `pandas`, `numpy`, `sklearn`\n",
    " - Model building and training: `torch`, `torch.nn`\n",
    " - Visualization: `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt # New import\n",
    "import numpy as np # New import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the model, train function, and evaluation.\n",
    "\n",
    "This part defines:\n",
    " - a simple **MLP (Multilayer Perceptron)** model;\n",
    " - two helper functions:\n",
    "   - `train()` → performs one epoch of training;\n",
    "   - `evaluate()` → computes accuracy and loss on validation/test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=64):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Training and evaluation loops\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for features, labels in loader:\n",
    "        features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in loader:\n",
    "            features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing\n",
    "\n",
    "The following helper functions:\n",
    " - load CSV data and separate features/labels;\n",
    " - normalize features using `StandardScaler`;\n",
    " - convert arrays to PyTorch tensors;\n",
    " - build DataLoaders for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_file, test_file):\n",
    "\n",
    "    # Load train/test CSVs\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    class_names = train_data[\"Outcome\"].unique()\n",
    "    print(f\"Classes: {class_names}\")\n",
    "\n",
    "    ### DROP non-feature ID columns (PatientID and CenterID)\n",
    "    train_data = train_data.drop(columns=['PatientID', 'CenterID'])\n",
    "    test_data = test_data.drop(columns=['PatientID', 'CenterID'])\n",
    "\n",
    "    ### One-hot encode Gender\n",
    "    train_data = pd.get_dummies(train_data, columns=['Gender'], drop_first=True)\n",
    "    test_data = pd.get_dummies(test_data, columns=['Gender'], drop_first=True)\n",
    "\n",
    "\n",
    "    train_data = train_data.fillna(0)\n",
    "    test_data = test_data.fillna(0)\n",
    "\n",
    "    # Feature and label columns\n",
    "    feature_names = train_data.columns[:-1]\n",
    "    print(f\"Features: {feature_names}\")\n",
    "    \n",
    "    X_train = train_data[feature_names].values\n",
    "    y_train = train_data[\"Outcome\"].values\n",
    "    X_test = test_data[feature_names].values\n",
    "    y_test = test_data[\"Outcome\"].values\n",
    "\n",
    "    # Encode class labels as integers\n",
    "    class_map = {label: idx for idx, label in enumerate(class_names)}\n",
    "    y_train = [class_map[label] for label in y_train]\n",
    "    y_test = [class_map[label] for label in y_test]\n",
    "\n",
    "    # Split training data into training and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(class_names)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, input_dim, output_dim\n",
    "\n",
    "# Normalize features with mean 0 and std 1\n",
    "def features_scaling(X_train, X_val, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Features scaled successfully.\")\n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled, scaler\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors.\n",
    "def convert_to_tensors(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor\n",
    "\n",
    "\n",
    "def create_dataloader(X_tensor, y_tensor, batch_size):\n",
    "    data = TensorDataset(X_tensor, y_tensor)\n",
    "    loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    return loader\n",
    "\n",
    "### Préparation des données pour le modèle serveur \n",
    "def preprocess_data_for_server(train_file, test_file):\n",
    "    # Logique complète de chargement, imputation, encodage et split pour le modèle serveur\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    \n",
    "    cols_to_fill = ['Tobacco', 'Alcohol', 'Performance status']\n",
    "    for col in cols_to_fill:\n",
    "        if col in train_data.columns:\n",
    "            train_data[col] = train_data[col].fillna(0.0)\n",
    "            test_data[col] = test_data[col].fillna(0.0)\n",
    "\n",
    "    train_data_processed = pd.get_dummies(train_data, columns=['Gender', 'CenterID'], drop_first=True)\n",
    "    test_data_processed = pd.get_dummies(test_data, columns=['Gender', 'CenterID'], drop_first=True)\n",
    "    train_data_processed.rename(columns={'Outcome': 'Class'}, inplace=True)\n",
    "    test_data_processed.rename(columns={'Outcome': 'Class'}, inplace=True)\n",
    "    \n",
    "    all_feature_cols = sorted([col for col in train_data_processed.columns if col not in ['PatientID', 'Class']])\n",
    "    \n",
    "    # Alignement des colonnes (features)\n",
    "    for df in [train_data_processed, test_data_processed]:\n",
    "        for col in all_feature_cols:\n",
    "            if col not in df.columns: df[col] = 0\n",
    "    \n",
    "    train_data_processed = train_data_processed.reindex(columns=all_feature_cols + ['Class'])\n",
    "    test_data_processed = test_data_processed.reindex(columns=all_feature_cols + ['Class'])\n",
    "    \n",
    "    feature_names = all_feature_cols\n",
    "    class_names = train_data_processed[\"Class\"].unique()\n",
    "    class_map = {label: idx for idx, label in enumerate(class_names)}\n",
    "    train_data_processed['Class'] = train_data_processed['Class'].apply(lambda x: class_map.get(x, x))\n",
    "    test_data_processed['Class'] = test_data_processed['Class'].apply(lambda x: class_map.get(x, x))\n",
    "    \n",
    "    X_full = train_data_processed[feature_names].values\n",
    "    y_full = train_data_processed[\"Class\"].values\n",
    "    X_test = test_data_processed[feature_names].values\n",
    "    y_test = test_data_processed[\"Class\"].values\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_full, y_full, test_size=0.2, random_state=42, stratify=y_full)\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(class_names)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, input_dim, output_dim, train_data, feature_names, class_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 64\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "PATIENCE = 5  # Early stopping patience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline execution\n",
    "\n",
    "Data loading and data loader creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled successfully.\n",
      "Device: cpu, Input dim: 10, Output dim: 2\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess server data\n",
    "\n",
    "# Préparation des données (Serveur et Clients)\n",
    "X_train_full, y_train_full, X_val_server, y_val_server, X_test_server, y_test_server, INPUT_DIM, OUTPUT_DIM, original_train_data, feature_names, class_map = preprocess_data_for_server(\n",
    "    \"../data_hn/data_hn_clinical_train.csv\", \"../data_hn/data_hn_clinical_test.csv\")\n",
    "\n",
    "X_train_server, X_val_server_scaled, X_test_server_scaled, scaler = features_scaling(X_train_full, X_val_server, X_test_server)\n",
    "\n",
    "X_train_tensor_server, y_train_tensor_server, X_val_tensor_server, y_val_tensor_server, X_test_tensor_server, y_test_tensor_server = convert_to_tensors(\n",
    "    X_train_server, y_train_full, X_val_server_scaled, y_val_server, X_test_server_scaled, y_test_server)\n",
    "\n",
    "# Split final pour l'entraînement centralisé\n",
    "X_train_server_final, X_val_server_final, y_train_server_final, y_val_server_final = train_test_split(\n",
    "    X_train_tensor_server, y_train_tensor_server, test_size=0.2, random_state=42, stratify=y_train_tensor_server.cpu().numpy()\n",
    ")\n",
    "\n",
    "train_loader_server = create_dataloader(X_train_server_final, y_train_server_final, BATCH_SIZE)\n",
    "val_loader_server = create_dataloader(X_val_server_final, y_val_server_final, BATCH_SIZE)\n",
    "test_loader_server = create_dataloader(X_test_tensor_server, y_test_tensor_server, BATCH_SIZE)\n",
    "\n",
    "print(f\"Device: {DEVICE}, Input dim: {INPUT_DIM}, Output dim: {OUTPUT_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Server training\n",
    "\n",
    "The server trains a baseline (centralized) model before FL.\n",
    " - Uses early stopping to prevent overfitting.\n",
    " - Prints training and validation accuracy per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/100 | Train Loss: 0.6462 | Train Acc: 0.6890 | Val Loss: 0.5934 | Val Acc: 0.7968\n",
      "New best validation loss. Resetting patience counter.\n",
      "Epoch 2/100 | Train Loss: 0.5423 | Train Acc: 0.7560 | Val Loss: 0.4891 | Val Acc: 0.7914\n",
      "New best validation loss. Resetting patience counter.\n",
      "Epoch 3/100 | Train Loss: 0.4882 | Train Acc: 0.7627 | Val Loss: 0.4541 | Val Acc: 0.7861\n",
      "New best validation loss. Resetting patience counter.\n",
      "Epoch 4/100 | Train Loss: 0.4712 | Train Acc: 0.7668 | Val Loss: 0.4487 | Val Acc: 0.7968\n",
      "New best validation loss. Resetting patience counter.\n",
      "Epoch 5/100 | Train Loss: 0.4562 | Train Acc: 0.7761 | Val Loss: 0.4467 | Val Acc: 0.7914\n",
      "New best validation loss. Resetting patience counter.\n",
      "Epoch 6/100 | Train Loss: 0.4436 | Train Acc: 0.7895 | Val Loss: 0.4469 | Val Acc: 0.7861\n",
      "No improvement. Patience counter: 1/5\n",
      "Epoch 7/100 | Train Loss: 0.4453 | Train Acc: 0.7882 | Val Loss: 0.4494 | Val Acc: 0.7861\n",
      "No improvement. Patience counter: 2/5\n",
      "Epoch 8/100 | Train Loss: 0.4380 | Train Acc: 0.7828 | Val Loss: 0.4369 | Val Acc: 0.8021\n",
      "New best validation loss. Resetting patience counter.\n",
      "Epoch 9/100 | Train Loss: 0.4258 | Train Acc: 0.8029 | Val Loss: 0.4401 | Val Acc: 0.8021\n",
      "No improvement. Patience counter: 1/5\n",
      "Epoch 10/100 | Train Loss: 0.4330 | Train Acc: 0.8043 | Val Loss: 0.4450 | Val Acc: 0.7861\n",
      "No improvement. Patience counter: 2/5\n",
      "Epoch 11/100 | Train Loss: 0.4227 | Train Acc: 0.8016 | Val Loss: 0.4385 | Val Acc: 0.8021\n",
      "No improvement. Patience counter: 3/5\n",
      "Epoch 12/100 | Train Loss: 0.4147 | Train Acc: 0.8056 | Val Loss: 0.4386 | Val Acc: 0.8075\n",
      "No improvement. Patience counter: 4/5\n",
      "Epoch 13/100 | Train Loss: 0.4103 | Train Acc: 0.8083 | Val Loss: 0.4441 | Val Acc: 0.8021\n",
      "No improvement. Patience counter: 5/5\n",
      "Early stopping triggered.\n",
      "Test Loss: 0.4065, Test Accuracy: 0.8082\n",
      "Confusion Matrix:\n",
      "[[108  39]\n",
      " [ 17 128]]\n",
      "F1 Score: 0.8072\n",
      "Precision: 0.8156\n",
      "Recall: 0.8082\n"
     ]
    }
   ],
   "source": [
    "####### Train server\n",
    "\n",
    "# Model, optimizer, and loss\n",
    "server_model = MLP(INPUT_DIM, OUTPUT_DIM, HIDDEN_DIM).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(server_model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping setup\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "\n",
    "# Training loop with early stopping\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(server_model, train_loader_server, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(server_model, val_loader_server, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping check (avoid overfitting)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        print(\"New best validation loss. Resetting patience counter.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience counter: {patience_counter}/{PATIENCE}\")\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "\n",
    "# -----Test the model------\n",
    "test_loss, test_acc = evaluate(server_model, test_loader_server, criterion)\n",
    "server_test_accuracy = test_acc\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Collect predictions for metrics\n",
    "server_model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader_server:\n",
    "        features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = server_model(features)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Confusion matrix and other metrics\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T08:41:04.736229Z",
     "start_time": "2025-10-08T08:41:04.734408Z"
    }
   },
   "source": [
    "#### Definition of Federated Learning parameters.\n",
    "\n",
    "The main parameters of FL are defined: **aggregation frequency, aggregation round, number of clients, and data structures** suitable for containing **client data and models**.\n",
    "\n",
    "These parameters are examples; modify and select them based on your data.\n",
    "\n",
    "Define FL setup:\n",
    " - how often to aggregate (`aggregation_freq`);\n",
    " - number of rounds (`aggregation_round`);\n",
    " - number of clients and placeholder structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation_round: 20\n"
     ]
    }
   ],
   "source": [
    "# FL parameters\n",
    "aggregation_freq = 5\n",
    "aggregation_round = round(EPOCHS / aggregation_freq)\n",
    "\n",
    "print(f\"Aggregation_round: {aggregation_round}\")\n",
    "clients_number = 5\n",
    "\n",
    "# FL clients data\n",
    "train_loader_clients = []\n",
    "val_loader_clients = []\n",
    "test_loader_clients = []\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fed_avg** is FL's **standard** aggregation method. It receives the weights of all models and **averages** each weight. The new model is composed of the **average of all model weights**.\n",
    "\n",
    "**fed_avg_weighted** is a **variant of fed_avg** that implements **weighted averaging**, taking into account the amount of data from each client.\n",
    "\n",
    "With the **fed_avg_w** variable, we choose whether to use the weighted version of FedAVG or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Implémentation FedAvg Standard et Pondéré (Task 3.1 B & C) ---\n",
    "\n",
    "def fed_avg(models_weights):\n",
    "    \"\"\"Standard FedAvg: Moyenne simple (égale) des poids.\"\"\"\n",
    "    new_state_dict = {}\n",
    "    num_clients = len(models_weights)\n",
    "    for key in models_weights[0].keys():\n",
    "        new_state_dict[key] = sum([m[key] for m in models_weights]) / num_clients\n",
    "    return new_state_dict\n",
    "\n",
    "#######def fed_avg_weighted(<parameters>):\n",
    "def fed_avg_weighted(models_weights, client_data_sizes):\n",
    "    \"\"\"Weighted FedAvg: Moyenne pondérée par la taille des données du client.\"\"\"\n",
    "    total_size = sum(client_data_sizes)\n",
    "    weights = [size / total_size for size in client_data_sizes]\n",
    "\n",
    "    new_state_dict = deepcopy(models_weights[0])\n",
    "    for key in new_state_dict.keys():\n",
    "        new_state_dict[key] = new_state_dict[key] * 0.0\n",
    "\n",
    "    for key in new_state_dict.keys():\n",
    "        for i, client_weights in enumerate(models_weights):\n",
    "            new_state_dict[key] += client_weights[key] * weights[i]\n",
    "    return new_state_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading and preprocessing (Clients)\n",
    "\n",
    "Creation of the global model from the server model: deepcopy(…)\n",
    "\n",
    "Loading of each client's data and preprocessing.\n",
    "\n",
    "Creation of models for each client\n",
    "\n",
    "\n",
    "\n",
    "Each client:\n",
    " - loads its local dataset;\n",
    " - scales features and converts to tensors;\n",
    " - creates DataLoaders;\n",
    " - initializes a model with the global weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting FL Simulation: Standard FedAvg ---\n",
      "\n",
      "--- Starting FL Simulation: Weighted FedAvg ---\n"
     ]
    }
   ],
   "source": [
    "# --- Partitionnement des Données Clients (Task 3.1 A) ---\n",
    "\n",
    "def partition_data_for_clients(original_train_data, feature_names, scaler, class_map):\n",
    "    # Partitionnement par CenterID pour simuler un environnement Non-IID\n",
    "    cols_to_fill = ['Tobacco', 'Alcohol', 'Performance status']\n",
    "    for col in cols_to_fill:\n",
    "        original_train_data[col] = original_train_data[col].fillna(0.0)\n",
    "\n",
    "    client_groups = original_train_data.groupby('CenterID')\n",
    "    unique_centers = list(client_groups.groups.keys())\n",
    "    \n",
    "    train_loader_clients = []\n",
    "    client_sizes = []\n",
    "    client_names = []\n",
    "\n",
    "    for center_id in unique_centers:\n",
    "        client_data = client_groups.get_group(center_id).copy()\n",
    "        \n",
    "        client_data_processed = pd.get_dummies(client_data, columns=['Gender', 'CenterID'], drop_first=True)\n",
    "        \n",
    "        X_client_df = pd.DataFrame(0, index=client_data_processed.index, columns=feature_names)\n",
    "        for col in client_data_processed.columns.intersection(feature_names):\n",
    "            X_client_df[col] = client_data_processed[col]\n",
    "\n",
    "        X_client = X_client_df.values\n",
    "        y_client = client_data_processed['Outcome'].values\n",
    "        \n",
    "        X_client_scaled = scaler.transform(X_client)\n",
    "        y_client_int = np.array([class_map.get(label, label) for label in y_client])\n",
    "        \n",
    "        X_tensor = torch.tensor(X_client_scaled, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y_client_int.tolist(), dtype=torch.long)\n",
    "        \n",
    "        loader = create_dataloader(X_tensor, y_tensor, BATCH_SIZE)\n",
    "        train_loader_clients.append(loader)\n",
    "        client_sizes.append(len(client_data))\n",
    "        client_names.append(center_id)\n",
    "        \n",
    "    return train_loader_clients, client_sizes, client_names\n",
    "\n",
    "\n",
    "\n",
    "# Partitionnement des données clients\n",
    "train_loader_clients, client_sizes, client_names = partition_data_for_clients(\n",
    "    original_train_data, feature_names, scaler, class_map)\n",
    "clients_number = len(client_names)\n",
    "\n",
    "# Simulations FL\n",
    "global_model_standard = deepcopy(server_model)\n",
    "std_acc, std_loss, std_client_acc = run_fl_simulation(\n",
    "    global_model_standard, train_loader_clients, client_sizes, test_loader_server, \n",
    "    aggregation_round, aggregation_freq, criterion, LEARNING_RATE, weighted=False)\n",
    "\n",
    "global_model_weighted = deepcopy(server_model)\n",
    "wtd_acc, wtd_loss, wtd_client_acc = run_fl_simulation(\n",
    "    global_model_weighted, train_loader_clients, client_sizes, test_loader_server, \n",
    "    aggregation_round, aggregation_freq, criterion, LEARNING_RATE, weighted=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we need to define the core of the FL, the aggregation and training cycles.\n",
    "\n",
    "\n",
    "You can draw **inspiration** from server training to train each client.\n",
    "\n",
    "For each round, you need to **aggregate the models** with the chosen function (pass the correct parameters based on the function).\n",
    "\n",
    "Also remember to **evaluate** the global model obtained and print the metrics.\n",
    "\n",
    "Then start a new round, and each client works with the new models.\n",
    "\n",
    "\n",
    "This is the **core FL training process**:\n",
    " - Each client trains locally for several epochs;\n",
    " - Local weights are collected;\n",
    " - Global model is updated by averaging;\n",
    " - Metrics are logged for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Boucle d'Agrégation et d'Entraînement FL (Task 3.1 D) ---\n",
    "\n",
    "def run_fl_simulation(global_model, train_loader_clients, client_sizes, test_loader_server, \n",
    "                      num_rounds, local_epochs, criterion, lr, weighted=False):\n",
    "    \n",
    "    global_model.train()\n",
    "    models = [deepcopy(global_model) for _ in train_loader_clients]\n",
    "    \n",
    "    global_test_accuracy_history = []\n",
    "    global_test_loss_history = []\n",
    "    \n",
    "    \n",
    "    print(f\"\\n--- Starting FL Simulation: {'Weighted' if weighted else 'Standard'} FedAvg ---\")\n",
    "\n",
    "    for round_num in range(1, num_rounds + 1):\n",
    "        \n",
    "        # 1. Local Training\n",
    "        client_weights_updates = []\n",
    "        for i, loader in enumerate(train_loader_clients):\n",
    "            \n",
    "            models[i].load_state_dict(global_model.state_dict())\n",
    "            optimizer = torch.optim.Adam(models[i].parameters(), lr=lr)\n",
    "            \n",
    "            for _ in range(local_epochs):\n",
    "                train_loss, train_acc = train(models[i], loader, optimizer, criterion)\n",
    "            \n",
    "            client_weights_updates.append(models[i].state_dict())\n",
    "        \n",
    "        # 2. Global Aggregation\n",
    "        if weighted:\n",
    "            new_global_weights = fed_avg_weighted(client_weights_updates, client_sizes)\n",
    "        else:\n",
    "            new_global_weights = fed_avg(client_weights_updates)\n",
    "        \n",
    "        global_model.load_state_dict(new_global_weights)\n",
    "        \n",
    "        # 3. Global Evaluation\n",
    "        test_loss, test_acc = evaluate(global_model, test_loader_server, criterion)\n",
    "        global_test_accuracy_history.append(test_acc)\n",
    "        global_test_loss_history.append(test_loss)\n",
    "        \n",
    "    # 4. Final Per-Client Accuracy \n",
    "    final_client_accuracies = []\n",
    "    for i, loader in enumerate(train_loader_clients):\n",
    "        _, client_acc = evaluate(global_model, loader, criterion)\n",
    "        final_client_accuracies.append(client_acc)\n",
    "        \n",
    "    return global_test_accuracy_history, global_test_loss_history, final_client_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation\n",
    "\n",
    "Test the model and print the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Federated Learning Models Validation ===\n",
      "Standard FedAvg - Global Test Accuracy History:\n",
      "[0.8082191780821918, 0.8116438356164384, 0.815068493150685, 0.8082191780821918, 0.8184931506849316, 0.815068493150685, 0.8184931506849316, 0.815068493150685, 0.8082191780821918, 0.791095890410959, 0.8013698630136986, 0.7945205479452054, 0.7808219178082192, 0.7773972602739726, 0.7808219178082192, 0.7808219178082192, 0.7842465753424658, 0.773972602739726, 0.7773972602739726, 0.7773972602739726]\n",
      "Final Per-client Accuracies: [0.8590604026845637, 0.8518518518518519, 0.7997587454764777]\n",
      "\n",
      "Weighted FedAvg - Global Test Accuracy History:\n",
      "[0.8082191780821918, 0.8082191780821918, 0.797945205479452, 0.8013698630136986, 0.7945205479452054, 0.8047945205479452, 0.791095890410959, 0.7876712328767124, 0.7773972602739726, 0.7773972602739726, 0.7876712328767124, 0.7671232876712328, 0.791095890410959, 0.797945205479452, 0.797945205479452, 0.797945205479452, 0.7876712328767124, 0.7808219178082192, 0.773972602739726, 0.7808219178082192]\n",
      "Final Per-client Accuracies: [0.7919463087248322, 0.8201058201058201, 0.841978287092883]\n",
      "\n",
      "Final Standard FedAvg Test Accuracy: 0.7774\n",
      "Final Weighted FedAvg Test Accuracy: 0.7808\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Federated Learning Models Validation ===\")\n",
    "\n",
    "# Standard FedAvg\n",
    "print(\"Standard FedAvg - Global Test Accuracy History:\")\n",
    "print(std_acc)\n",
    "print(\"Final Per-client Accuracies:\", std_client_acc)\n",
    "\n",
    "# Weighted FedAvg\n",
    "print(\"\\nWeighted FedAvg - Global Test Accuracy History:\")\n",
    "print(wtd_acc)\n",
    "print(\"Final Per-client Accuracies:\", wtd_client_acc)\n",
    "\n",
    "# Pour un résumé complet, on peut aussi afficher la dernière valeur globale\n",
    "print(f\"\\nFinal Standard FedAvg Test Accuracy: {std_acc[-1]:.4f}\")\n",
    "print(f\"Final Weighted FedAvg Test Accuracy: {wtd_acc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs\n",
    "\n",
    "This code generates and saves key results from the Federated Learning experiments. It plots data distribution per client, global accuracy and loss over rounds (comparing Standard vs. Weighted FedAvg), and per-client accuracies. Finally, it saves all metrics in CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Génération des Graphiques (Task 3.2) ---\n",
    "\n",
    "# ------> Global accuracy vs. rounds\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Courbes de précision globale du modèle à chaque round\n",
    "plt.plot(range(1, aggregation_round + 1), std_acc, label='Standard FedAvg', marker='o')\n",
    "plt.plot(range(1, aggregation_round + 1), wtd_acc, label='Weighted FedAvg', marker='x')\n",
    "plt.axhline(y=server_test_accuracy, color='r', linestyle='--', label=f'Centralisé (Baseline) Acc: {server_test_accuracy:.4f}')\n",
    "plt.title('Précision (Accuracy) Globale de Test vs. Rounds de Communication')\n",
    "plt.xlabel('Round de Communication')\n",
    "plt.ylabel('Précision Globale de Test')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('fl_global_accuracy_vs_rounds.png')\n",
    "plt.close()\n",
    "\n",
    "# ------> Global loss vs. rounds\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Courbes de perte globale du modèle à chaque round\n",
    "plt.plot(range(1, aggregation_round + 1), std_loss, label='Standard FedAvg', marker='o')\n",
    "plt.plot(range(1, aggregation_round + 1), wtd_loss, label='Weighted FedAvg', marker='x')\n",
    "plt.title('Perte (Loss) Globale de Test vs. Rounds de Communication')\n",
    "plt.xlabel('Round de Communication')\n",
    "plt.ylabel('Perte Globale de Test')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('fl_global_loss_vs_rounds.png')\n",
    "plt.close()\n",
    "\n",
    "# ------> Per-client accuracy (bar chart)\n",
    "x = np.arange(clients_number)\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Barres pour Standard FedAvg\n",
    "rects1 = ax.bar(x - width/2, std_client_acc, width, label='Standard FedAvg', color='C0')\n",
    "# Barres pour Weighted FedAvg\n",
    "rects2 = ax.bar(x + width/2, wtd_client_acc, width, label='Weighted FedAvg', color='C1')\n",
    "ax.set_ylabel('Précision Finale du Client (sur données locales)')\n",
    "ax.set_xlabel('ID Client (CenterID)')\n",
    "ax.set_title('Comparaison de la Précision Finale par Client')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(client_names)\n",
    "ax.legend()\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.savefig('fl_per_client_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# ------> Weighted vs. Unweighted convergence\n",
    "# Overlay accuracy curves for both versions (déjà inclus dans Global Accuracy vs rounds)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, aggregation_round + 1), std_acc, label='Standard FedAvg', marker='o')\n",
    "plt.plot(range(1, aggregation_round + 1), wtd_acc, label='Weighted FedAvg', marker='x')\n",
    "plt.title('Convergence: Standard vs Weighted FedAvg')\n",
    "plt.xlabel('Round de Communication')\n",
    "plt.ylabel('Précision Globale de Test')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('fl_weighted_vs_unweighted_convergence.png')\n",
    "plt.close()\n",
    "\n",
    "# ------> Data distribution histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Histogramme montrant la taille des datasets par client\n",
    "plt.bar(client_names, client_sizes, color='skyblue')\n",
    "plt.title('Distribution des données par client (Simulation Non-IID)')\n",
    "plt.xlabel('ID Client (CenterID)')\n",
    "plt.ylabel('Nombre d\\'échantillons')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.savefig('fl_client_data_distribution.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Interpretation paragraph\n",
    "\n",
    " - **Standard FedAvg** treats all clients equally regardless of dataset size, which may bias results toward smaller clients.\n",
    " - **Weighted FedAvg** gives larger clients more influence, leading to more stable and fairer global models.\n",
    " - In most experiments, **Weighted FedAvg** converges faster and achieves higher overall accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
